---
title: "Chunk-size Test: Memory"
author: "Ruoxi Liu"
date: "6/18/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,fig.width = 12, fig.height = 10)
```

```{r}
library(tidyr)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(grid)
library(here)
```

```{r}
mem_blockApp <- read.csv("/Users/April30/benchmark-hdf5-clustering/ongoing_analysis/ChunkTest/TENxBrainData/Output/new_mem.csv", header=TRUE, sep=",")
mem_blockApp$label2 <- factor(mem_blockApp$label2, levels = c("mbkmeans", "Best-HDF5", "Worst-HDF5"))
mem_blockApp$calc_label <- factor(mem_blockApp$calc_label, levels = c("Whole", "Centroid", "Labels"))
mem_blockApp <- na.omit(mem_blockApp)

mem_old <- read.csv("/Users/April30/benchmark-hdf5-clustering/ongoing_analysis/ChunkTest/TENxBrainData/Output/before_BloackApp/new_mem_old.csv", header=TRUE, sep=",")
mem_old$label2 <- factor(mem_old$label2, levels = c("mbkmeans-OLD", "Best-HDF5-OLD", "Worst-HDF5-OLD"))
mem_old$calc_label <- factor(mem_old$calc_label, levels = c("Whole", "Centroid", "Labels"))

mem <- rbind(mem_blockApp, mem_old)
```

# Memory
```{r}
p_mem <- mem_blockApp %>% 
  #filter(calc_label=="full") %>%
  dplyr::group_by(observations, abs.batch.size, label2) %>% 
  ggplot(aes(x = as.factor(abs.batch.size), y = memory/1024, color = label2)) +
          geom_point()+
    labs(title = "Memory: Three Measures Side by Side (BlockApply)") + 
    xlab("Absolute Batch Size")+
    ylab("Memory(GB)")+
    facet_grid(~observations+calc_label)
p_mem
```

```{r}
p_mem_old <- mem_old %>% 
  filter(observations==75000|observations==500000) %>%
  dplyr::group_by(observations, abs.batch.size, label2) %>% 
  ggplot(aes(x = as.factor(abs.batch.size), y = memory/1024, color = label2)) +
          geom_point()+
    labs(title = "Memory: Three Measures Side by Side (getrow)") + 
    xlab("Absolute Batch Size")+
    ylab("Memory(GB)")+
    facet_grid(~observations+calc_label)
p_mem_old
```
### Take aways:

1. mbkmeans increases memory with batch size. This makes sense. (with blockApply, this is not true...)

2. memory use with HDF5 mbkmeans does not increase with batch size. this does not make sense. We would expect a small increase in memory consumption as the batch size increases. The difference is that the data are not loaded into memory.

3. There is no difference in memory between best and worst HDF5. This does not make sense.

4. Computing the centroids is the part that takes the most amount of memory and it increases with batch size. In contrast, the labeling part does not increase with batch size. This makes snese because we are only loading in 1 obs into memory at a time for the labeling. 


# Compare blockApply with getrow
```{r}
p_mem_compare_mbkm1 <- mem %>% 
  filter(calc_label=="Labels") %>%
  filter(label2=="mbkmeans"|label2=="mbkmeans-OLD") %>%
  dplyr::group_by(observations, abs.batch.size, label2) %>% 
  ggplot(aes(x = as.factor(abs.batch.size), y = memory/1024, color = label2)) +
          geom_point()+
    xlab("Absolute Batch Size")+
    ylab("Memory(GB)")+
    labs(title = "Memory Comparison: mbkmeans computing the labels") + 
    facet_grid(~observations)
p_mem_compare_mbkm1
```
```{r}
p_mem_compare_mbkm2 <- mem %>% 
  filter(calc_label=="Whole") %>%
  filter(label2=="mbkmeans"|label2=="mbkmeans-OLD") %>%
  dplyr::group_by(observations, abs.batch.size, label2) %>% 
  ggplot(aes(x = as.factor(abs.batch.size), y = memory/1024, color = label2)) +
          geom_point()+
    labs(title = "Memory Comparison: mbkmeans whole process") + 
    xlab("Absolute Batch Size")+
    ylab("Memory(GB)")+
    facet_grid(~observations)
p_mem_compare_mbkm2
```

```{r}
p_mem_compare_hdf51 <- mem %>% 
  filter(calc_label=="Labels") %>%
  filter(label2=="Best-HDF5"|label2=="Best-HDF5-OLD") %>%
  dplyr::group_by(observations, abs.batch.size, label2) %>% 
  ggplot(aes(x = as.factor(abs.batch.size), y = memory/1024, color = label2)) +
          geom_point()+
    xlab("Absolute Batch Size")+
    ylab("Memory(GB)")+
    labs(title = "Memory Comparison: HDF5 computing the labels") + 
    facet_grid(~observations)
p_mem_compare_hdf51
```
```{r}
p_mem_compare_hdf52 <- mem %>% 
  filter(calc_label=="Whole") %>%
  filter(label2=="Best-HDF5"|label2=="Best-HDF5-OLD") %>%
  dplyr::group_by(observations, abs.batch.size, label2) %>% 
  ggplot(aes(x = as.factor(abs.batch.size), y = memory/1024, color = label2)) +
          geom_point()+
    labs(title = "Memory Comparison: HDF5 whole process") + 
    xlab("Absolute Batch Size")+
    ylab("Memory(GB)")+
    facet_grid(~observations)
p_mem_compare_hdf52
```

```{r eval = FALSE, echo = FALSE}
# Supp Figures: Break down the side by side figure
## 1.1 Memory for the Whole Process (using BlockApply)
p_mem_blockApp <- mem_blockApp %>% 
  filter(calc_label=="Whole") %>%
  dplyr::group_by(observations, abs.batch.size, label2) %>% 
  ggplot(aes(x = as.factor(abs.batch.size), y = memory/1024, color = label2)) +
          geom_point()+
    labs(title = "1.1: HDF5 Geometry: Memory for the Whole Process") + 
    xlab("Absolute Batch Size")+
    ylab("Memory(GB)")+
    facet_grid(~observations)
p_mem_blockApp
```


```{r eval = FALSE, echo = FALSE}
## 1.2 Memory for the Computing Centorids (using BlockApply)
p_mem_blockApp_centorids <- mem_blockApp %>% 
  filter(calc_label=="Centroid") %>%
  dplyr::group_by(observations, abs.batch.size, label2) %>% 
  ggplot(aes(x = as.factor(abs.batch.size), y = memory/1024, color = label2)) +
          geom_point()+
    xlab("Absolute Batch Size")+
    ylab("Memory(GB)")+
    labs(title = "1.2: HDF5 Geometry: Memory for Computing Centorids") + 
    facet_grid(~observations)
p_mem_blockApp_centorids
```


```{r eval = FALSE, echo = FALSE}
## 1.3 Memory for the Predicting Labels (using BlockApply)
p_mem_blockApp_labels <- mem_blockApp %>% 
  filter(calc_label=="Labels") %>%
  dplyr::group_by(observations, abs.batch.size, label2) %>% 
  ggplot(aes(x = as.factor(abs.batch.size), y = memory/1024, color = label2)) +
          geom_point()+
    xlab("Absolute Batch Size")+
    ylab("Memory(GB)")+
    labs(title = "1.3: HDF5 Geometry: Memory for Predicting Labels") + 
    facet_grid(~observations)
p_mem_blockApp_labels
```

```{r eval = FALSE, echo = FALSE}
files <- list.files(path= here("ongoing_analysis","ChunkTest/TENxBrainData/Output"), pattern="^time_[a-z]+.csv", full.names=TRUE, recursive=FALSE)
time_table <- NULL
for (i in (1:length(files))){
  temp_table <- read.csv(file = files[i], header=TRUE, sep=",")
  time_table <- rbind(time_table, temp_table)
}

files <- list.files(path= here("ongoing_analysis","ChunkTest/TENxBrainData/Output"), pattern="^mem_[a-z]+.csv", full.names=TRUE, recursive=FALSE)
mem_table <- NULL
for (i in (1:length(files))){
  temp_table <- read.csv(file = files[i], header=TRUE, sep=",")
  mem_table <- rbind(mem_table, temp_table)
}
```

```{r eval = FALSE, echo = FALSE}
time_table %>% 
  gather("time_type", "time", -c(1:4,8:10)) %>%
  filter(observations==500000) %>%
  dplyr::group_by(geometry, observations, abs.batch.size) %>% 
  ggplot(aes(x = as.factor(abs.batch.size), y = time, color = geometry)) +
          #geom_line()+
          geom_point()+
          labs(title = "HDF5 Geometry: Time") + 
  facet_grid(time_type~observations, scales = "free")
```
```{r eval = FALSE, echo = FALSE}
mem_table %>% 
  dplyr::filter(!is.na(calc_label)) %>%
  dplyr::group_by(geometry, observations, abs.batch.size, calc_label) %>% 
  #dplyr::filter(observations == 75000) %>%
  #dplyr::summarize(mean = mean(time), 
   #                sd = sd(time)) %>% 
  ggplot(aes(x = as.factor(abs.batch.size), y = memory, color = geometry)) +
          #geom_line()+
          geom_point()+
          labs(title = "HDF5 Geometry: Memory") + 
  facet_wrap(~observations+calc_label, scales="free")
```

```{r eval = FALSE, echo = FALSE}
files <- list.files(path= here("ongoing_analysis","ChunkTest"), pattern="*.csv", full.names=TRUE, recursive=FALSE)

final_table <- NULL

for (i in (1:length(files))){
  temp_table <- read.csv(file = files[i], header=TRUE, sep=",")[,1:5]
  final_table <- rbind(final_table, temp_table)
}
```

```{r eval = FALSE, echo = FALSE}
final_table %>% 
  dplyr::group_by(dimension, observations, batch_size) %>% 
  dplyr::summarize(mean = mean(time), 
                   sd = sd(time)) %>% 
  ggplot(aes(x = observations, y = mean, color = dimension)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Observation vs. time w/ increading Batch Size") + 
  facet_wrap(~batch_size)
```

```{r eval = FALSE, echo = FALSE}
final_table %>% 
  #dplyr::filter(dimension != "one") %>%
  dplyr::filter(observations < 250000) %>%
  dplyr::group_by(dimension, observations, batch_size) %>% 
  dplyr::summarize(mean = mean(time), 
                   sd = sd(time)) %>% 
  ggplot(aes(x = observations, y = mean, color = dimension)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Observation vs. time w/ increading Batch Size") + 
  facet_wrap(~batch_size)
```

