---
title: "Benchmark Summary"
author: "Ruoxi Liu"
date: "6/19/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 14, fig.height = 10)
```

```{r}
library(tidyr)
library(ggplot2)
library(cowplot)
library(gridExtra)
library(dplyr)
library(grid)
library(here)
```

# Memory Summary
```{r}
files_mem <- list.files(path= here("output_tables", "mem"), pattern="*.csv", full.names=TRUE, recursive=FALSE)

mem_table <- NULL

for (i in (1:length(files_mem))){
  temp_table <- read.csv(file = files_mem[i], header=TRUE, sep=",")
  mem_table <- rbind(mem_table, temp_table)
}
mem_table <- mem_table %>% 
  mutate(method = factor(method, levels = c("kmeans", "mbkmeans", "hdf5")), 
         batch_size_perc = factor(scales::percent(mem_table$batch_size), 
                             levels = c("0.5%", "1.0%", "5.0%", "10.0%", "20.0%", "50.0%", "80.0%", "100.0%")))
levels(mem_table$method) <- c("kmeans-new", "mbkmeans-new", "mbkmean_hdf5-new")
mem_table <- na.omit(mem_table)
```

```{r}
files_mem_old <- list.files(path= here("output_tables", "mem", "Before_Patch_0707"), pattern="*.csv", full.names=TRUE, recursive=FALSE)

mem_table_old <- NULL

for (i in (1:length(files_mem_old))){
  temp_table <- read.csv(file = files_mem_old[i], header=TRUE, sep=",")
  mem_table_old<- rbind(mem_table_old, temp_table)
}
mem_table_old <- mem_table_old %>% 
  mutate(method = factor(method, levels = c("kmeans", "mbkmeans", "hdf5")), 
         batch_size_perc = factor(scales::percent(mem_table_old$batch_size), 
                             levels = c("0.5%", "1.0%", "5.0%", "10.0%", "20.0%", "50.0%", "80.0%", "100.0%")))
levels(mem_table_old$method) <- c("kmeans-old", "mbkmeans-old", "mbkmean_hdf5-old")

mem_table_total <- rbind(mem_table, mem_table_old)
mem_table_total <- na.omit(mem_table_total)
```

```{r}
mem_table_bash <- read.csv(file = here("main/Memory_Bash/mem_output.csv"), header=TRUE, sep=",")
mem_table_bash <- mem_table_bash %>% 
  mutate(method = factor(method, levels = c("kmeans", "mbkmeans", "hdf5")), 
         batch_size_perc = factor(scales::percent(mem_table_bash$batch_size), 
                             levels = c("0.5%", "1.0%", "5.0%", "10.0%", "20.0%", "50.0%", "80.0%", "100.0%")))
#levels(mem_table_old$method) <- c("kmeans-bash", "mbkmeans-bash", "mbkmean_hdf5-bash")
```

## I. Fix batch size and k (study observation vs. memory)
### I-1-1. New results (seperating simulation and test)
```{r}
p_mem_obs_all <- mem_table %>%
  #dplyr::filter(!(observations %in% c(1000000)))%>%
  #dplyr::filter((observations <= 200000))%>%
  dplyr::group_by(method, observations, batch_size_perc) %>% 
  dplyr::summarize(mean = mean(memory), 
                   sd = sd(memory)) %>% 
  ggplot(aes(x = observations/1e3, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Assessing Memory Usage for Increasing No. Obs\n(fixed batch size) [B=6 for small, B=3 for large] ") + 
        xlab("Number of cells (thousands)") + 
        ylab("Memory (Mb)") + 
  facet_wrap(~batch_size_perc, scales = "free") + 
  theme(legend.position = "top", legend.justification= "center") +
  scale_color_discrete(name = "Method")

p_mem_obs_all
```
### I-1-2. New results, removing kmenas to see the cross between mbkmeans and hdf5
```{r, warning=FALSE}
p_mem_obs <- mem_table %>%
  dplyr::filter(!(method %in% c("kmeans-new")))%>%
  #dplyr::filter(!(observations %in% c(1000000)))%>%
  #dplyr::filter((observations <= 200000))%>%
  dplyr::group_by(method, observations, batch_size_perc) %>% 
  dplyr::summarize(mean = mean(memory), 
                   sd = sd(memory)) %>% 
  ggplot(aes(x = observations/1e3, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Assessing Memory Usage for Increasing No. Obs\n(fixed batch size)  [B=6 for small, B=3 for large]") + 
        xlab("Number of cells (thousands)") + 
        ylab("Memory (Mb)") + 
  facet_wrap(~batch_size_perc, scales = "free") + 
  theme(legend.position = "top", legend.justification= "center") +
  scale_color_discrete(name = "Method")

p_mem_obs
```
### I-2-1. Compare new results with before-patch results (hdf5)
```{r, warning=FALSE}
p_mem_patch_hdf5 <- mem_table_total %>%
  dplyr::filter(!(method %in% c("kmeans-old", "kmeans-new","mbkmeans-old","mbkmeans-new" )))%>%
  dplyr::filter(!(observations %in% c(1000000)))%>%
  dplyr::filter(!(batch_size_perc %in% c("100.0%")))%>%
  dplyr::group_by(method, observations, batch_size_perc) %>% 
  dplyr::summarize(mean = mean(memory), 
                   sd = sd(memory)) %>% 
  ggplot(aes(x = observations/1e3, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Assessing Memory Usage for Increasing No. Obs\n(fixed batch size) [B=6 for small, B=3 for large]") + 
        xlab("Number of cells (thousands)") + 
        ylab("Memory (Mb)") + 
  facet_wrap(~batch_size_perc, scales = "free") + 
  theme(legend.position = "top", legend.justification= "center") +
  scale_color_discrete(name = "Method")

p_mem_patch_hdf5
```
### I-2-2. Compare new results with before-patch results (mbkmeans)
```{r, warning=FALSE}
p_mem_patch_mbkm <- mem_table_total %>%
  dplyr::filter(!(method %in% c("kmeans-old", "kmeans-new","mbkmean_hdf5-old","mbkmean_hdf5-new" )))%>%
  dplyr::filter(!(observations %in% c(1000000)))%>%
  dplyr::group_by(method, observations, batch_size_perc) %>% 
  dplyr::summarize(mean = mean(memory), 
                   sd = sd(memory)) %>% 
  ggplot(aes(x = observations/1e3, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Assessing Memory Usage for Increasing No. Obs\n(fixed batch size) [B=6 for small, B=3 for large]") + 
        xlab("Number of cells (thousands)") + 
        ylab("Memory (Mb)") + 
  facet_wrap(~batch_size_perc, scales = "free") + 
  theme(legend.position = "top", legend.justification= "center") +
  scale_color_discrete(name = "Method")

p_mem_patch_mbkm
```
### I-3. Compare R results with system results.
```{r}
mem_table_total2 <- rbind(mem_table, mem_table_bash)

p_mem_obs_total2 <- mem_table_total2 %>%
  dplyr::filter(!(method %in% c("kmeans-old", "kmeans-new","mbkmeans-old","mbkmeans-new" )))%>%
  dplyr::filter(!(observations %in% c(1000000)))%>%
  #dplyr::filter((observations %in% c(1000, 5000, 25000, 75000, 100000, 175000)))%>%
  dplyr::group_by(method, observations, batch_size_perc) %>% 
  dplyr::summarize(mean = mean(memory), 
                   sd = sd(memory)) %>% 
  ggplot(aes(x = observations/1e3, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Assessing Memory Usage for Increasing No. Obs\n(fixed batch size) [B=6 for small, B=3 for large]") + 
        xlab("Number of cells (thousands)") + 
        ylab("Memory (Mb)") + 
  facet_wrap(~batch_size_perc, scales = "free") + 
  theme(legend.position = "top", legend.justification= "center") +
  scale_color_discrete(name = "Method")

p_mem_obs_total2
```

## II. Fix observation and k (study effects of batch size)
```{r, warning=FALSE}
p_mem_batch <- mem_table %>%
  #dplyr::filter(!(method %in% c("kmeans-new")))%>%
  dplyr::filter(!(observations %in% c(400000,450000)))%>%
  dplyr::group_by(method, observations, batch_size) %>% 
  dplyr::summarize(mean = mean(memory), 
                   sd = sd(memory)) %>% 
  ggplot(aes(x = batch_size, y = mean, color = method)) +
          geom_line() +
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd))+
        labs(title = "Assessing Memory Usage for Increasing Batch Size\n(fixed number of observations) [B=6 for small, B=3 for large]") + 
        xlab("Batch size") + 
        ylab("Memory (Mb)") + 
  facet_wrap(~observations, scales = "free") + 
  theme(legend.position = "top", legend.justification= "center") +  
  scale_color_discrete(name = "Method")

p_mem_batch
```

# Time Summary
```{r}
files_time <- list.files(path= here("output_tables", "time"), pattern="*.csv", full.names=TRUE, recursive=FALSE)
files_time_old <- list.files(path= here("output_tables", "time", "Before_Patch_0707"), pattern="*.csv", full.names=TRUE, recursive=FALSE)

time_table <- NULL
time_table_old <- NULL

for (i in (1:length(files_time))){
  temp_table <- read.csv(file = files_time[i], header=TRUE, sep=",")
  time_table <- rbind(time_table, temp_table)
}
time_table <- time_table %>% 
  mutate(method = factor(method, levels = c("kmeans", "mbkmeans", "hdf5")), 
         batch_size_perc = factor(scales::percent(time_table$batch_size), 
                             levels = c("0.5%", "1.0%", "5.0%", "10.0%", "20.0%", "50.0%", "80.0%", "100.0%")))
levels(time_table$method) <- c("kmeans-new", "mbkmeans-new", "mbkmean_hdf5-new")

for (i in (1:length(files_time_old))){
  temp_table <- read.csv(file = files_time_old[i], header=TRUE, sep=",")
  time_table_old <- rbind(time_table_old, temp_table)
}
time_table_old <- time_table_old %>% 
  mutate(method = factor(method, levels = c("kmeans", "mbkmeans", "hdf5")), 
         batch_size_perc = factor(scales::percent(time_table_old$batch_size), 
                             levels = c("0.5%", "1.0%", "5.0%", "10.0%", "20.0%", "50.0%", "80.0%", "100.0%")))
levels(time_table_old$method) <- c("kmeans-old", "mbkmeans-old", "mbkmean_hdf5-old")

time_table_total <- rbind(time_table, time_table_old)
```

## I-1 Fix batch size and k (study observation vs. time)
```{r, warning=FALSE, fig.height=20}
p_time_obs <- time_table %>% gather(key = "time_type", value = "time", -c(B:method), -batch_size_perc)  %>%
  dplyr::group_by(method, observations, batch_size_perc, time_type) %>% 
  dplyr::summarize(mean = mean(time), 
                   sd = sd(time)) %>% 
  ggplot(aes(x = observations/1e3, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Assessing Time for Increasing No. Obs\n(fixed batch size) [B=10 for small, B=3 for large]") + 
        xlab("Number of cells (thousands)") + 
        ylab("Time (Seconds)") + 
  facet_grid(batch_size_perc~time_type, scale = "free") + 
  scale_color_discrete(name = "Method")

p_time_obs
```
```{r, warning=FALSE}
p_sys_time_obs <- time_table %>% gather(key = "time_type", value = "time", -c(B:method), -batch_size_perc)  %>%
  dplyr::group_by(method, observations, batch_size_perc, time_type) %>% 
  filter(time_type == "system_time") %>%
  dplyr::summarize(mean = mean(time), 
                   sd = sd(time)) %>% 
  ggplot(aes(x = observations/1e3, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Assessing Time for Increasing No. Obs\n(fixed batch size) [B=10 for small, B=3 for large]") + 
        xlab("Number of cells (thousands)") + 
        ylab("Time (Seconds)") + 
  facet_wrap(batch_size_perc~time_type, scale = "free") + 
  scale_color_discrete(name = "Method")

p_sys_time_obs
```
## I-2 Fix observation and k (study effects of batch size)
```{r, warning=FALSE, fig.height=20}
p_time_batch <- time_table %>% gather(key = "time_type", value = "time", -c(B:method), -batch_size_perc)  %>%
  dplyr::group_by(method, observations, batch_size, time_type) %>% 
  dplyr::summarize(mean = mean(time), 
                   sd = sd(time)) %>% 
  ggplot(aes(x = batch_size, y = mean, color = method)) +
          geom_line() +
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd))+
        labs(title = "") + 
        xlab("Batch size") + 
        ylab("time (Seconds)") + 
  facet_grid(observations~time_type, scales = "free") + 
  scale_color_discrete(name = "Method")

p_time_batch
```
# Accuracy Summary
```{r}
files_acc <- list.files(path= here("output_tables", "acc"), pattern="*.csv", full.names=TRUE, recursive=FALSE)

acc_table <- NULL

for (i in (1:length(files_acc))){
  temp_table <- read.csv(file = files_acc[i], header=TRUE, sep=",")
  acc_table <- rbind(acc_table, temp_table)
}
acc_table <- acc_table %>% 
  mutate(method = factor(method, levels = c("kmeans", "mbkmeans", "hdf5")), 
         batch_size_perc = factor(scales::percent(acc_table$batch_size), 
                             levels = c("0.5%", "1.0%", "5.0%", 
                                        "10.0%", "20.0%","35.0%", "50.0%"))) %>%
  transform(normal_WCSS = WCSS/observations)
levels(acc_table$method) <- c("kmeans-new", "mbkmeans-new", "mbkmean_hdf5-new")
```
## I. Fix batch size and k (study observation vs. accuracy) 
### I-1-1 New results: ARI (all small data points, up to 10k)
```{r, warning=FALSE, eval=FALSE}
p_ari_obs_line <- acc_table %>% 
  #dplyr::filter(!(method == "kmeans"))%>%
  dplyr::filter((observations %in% c(500, 2000, 4000, 5000)))%>%
  dplyr::group_by(method, observations, batch_size_perc) %>% 
  dplyr::summarize(mean = mean(ARI), 
                   sd = sd(ARI)) %>% 
  ggplot(aes(x = observations/1e3, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Assessing ARI for Increasing No. Obs\n(fixed batch size) [B=50 for small (up to 25k), B=10 for large]") + 
        xlab("Number of cells (thousands)") + 
        ylab("ARI") + 
  facet_wrap(~batch_size_perc, scale = "free") + 
  scale_color_discrete(name = "Method")

p_ari_obs_line
```
### I-1-2 New results: WCSS (all small data points, up to 25k)
```{r, warning=FALSE}
p_wcss_obs_line <- acc_table %>% 
  #dplyr::filter(observations %in% c(1000,5000))%>%
  dplyr::filter((observations %in% c(500, 2000, 4000, 5000, 6000, 8000, 10000)))%>%
  dplyr::group_by(method, observations, batch_size_perc) %>% 
  dplyr::summarize(mean = mean(normal_WCSS), 
                   sd = sd(normal_WCSS)) %>% 
  ggplot(aes(x = observations/1e3, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Assessing WCSS for Increasing No. Obs\n(fixed batch size) [B=50 for small (up to 25k), B=10 for large]") + 
        xlab("Number of cells (thousands)") + 
        ylab("Normalized WCSS") + 
  facet_wrap(~batch_size_perc, scale = "free") + 
  theme(legend.position = "top", legend.justification= "center") + 
  scale_color_discrete(name = "Method")

p_wcss_obs_line
```
## II. Fix observation and k (study batch size vs. accuracy) 
### II-1-1 New results: ARI
```{r}
p_ari_batch_line <- acc_table %>% 
  dplyr::filter((observations %in% c(500, 2000, 4000, 5000, 6000, 8000, 10000)))%>%
  dplyr::group_by(method, observations, batch_size) %>% 
  dplyr::summarize(mean = mean(ARI), 
                   sd = sd(ARI)) %>% 
  ggplot(aes(x = batch_size, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          #geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
          #      position=position_dodge(0.05))+
        labs(title = "Assessing ARI for Increasing Batch Size\n(fixed number of observations) [B=50 for small (up to 25k), B=10 for large]") + 
        xlab("Batch Size") + 
        ylab("ARI")+ 
  facet_wrap(~factor(observations), scale = "free") + 
  theme(legend.position = "top", legend.justification= "center")+ 
  scale_color_discrete(name = "Method")

p_ari_batch_line
```
```{r}
p_wcss_batch_line <- acc_table %>% 
  dplyr::filter((observations %in% c(500, 2000, 4000, 5000, 6000, 8000, 10000)))%>%
  dplyr::group_by(method, observations, batch_size) %>% 
  dplyr::summarize(mean = mean(normal_WCSS), 
                   sd = sd(normal_WCSS)) %>% 
  ggplot(aes(x = batch_size, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          #geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
          #      position=position_dodge(0.05))+
        labs(title = "Assessing WCSS for Increasing Batch Size\n(fixed number of observations) [B=50 for small (up to 25k), B=10 for large]") + 
        xlab("Batch Size") + 
        ylab("Normalized WCSS")+ 
  facet_wrap(~factor(observations), scale = "free") + 
  theme(legend.position = "top", legend.justification= "center")+ 
  scale_color_discrete(name = "Method")

p_wcss_batch_line
```
## III. Number of iterations
### III-1 Iterations vs. Observations
```{r}
p_iter_obs <- acc_table %>% 
  #dplyr::filter(!(method == "kmeans"))%>%
  #dplyr::filter((observations %in% c(500, 2000, 4000, 5000, 6000, 8000, 10000)))%>%
  dplyr::group_by(method, observations, batch_size_perc) %>% 
  dplyr::summarize(mean = mean(iterations), 
                   sd = sd(iterations)) %>% 
  ggplot(aes(x = observations/1e3, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
          scale_x_log10()+
        labs(title = "Number of Iterations for Increasing No. Obs\n(fixed batch size) [B=50 for small (up to 25k), B=10 for large]") + 
        xlab("Number of cells (thousands)") + 
        ylab("Iterations") + 
  facet_wrap(~batch_size_perc, scale = "free") + 
  scale_color_discrete(name = "Method")

p_iter_obs
```
### III-2 Iterations vs. Batch Size
```{r}
p_iter_batch <- acc_table %>% 
  #dplyr::filter((observations %in% c(500, 2000, 4000, 5000, 6000, 8000, 10000)))%>%
  dplyr::group_by(method, observations, batch_size) %>% 
  dplyr::summarize(mean = mean(iterations), 
                   sd = sd(iterations)) %>% 
  ggplot(aes(x = batch_size, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          #geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
          #      position=position_dodge(0.05))+
        labs(title = "Iterations for Increasing Batch Size\n(fixed number of observations) [B=50 for small (up to 25k), B=10 for large]") +
        xlab("Batch Size") + 
        ylab("Number of Iterations")+ 
  facet_wrap(~factor(observations), scale = "free") + 
  theme(legend.position = "top", legend.justification= "center")+ 
  scale_color_discrete(name = "Method")

p_iter_batch
```
# IV Warnings?
```{r}
print(table(acc_table$fault))
print(sum(is.na(acc_table$fault)))
```

# V Increasing K
```{r}
files_k_acc <- list.files(path= here("output_tables", "Varying_k", "acc"), pattern="*.csv", full.names=TRUE, recursive=FALSE)
files_k_mem <- list.files(path= here("output_tables", "Varying_k", "mem"), pattern="*.csv", full.names=TRUE, recursive=FALSE)
files_k_time <- list.files(path= here("output_tables", "Varying_k", "time"), pattern="*.csv", full.names=TRUE, recursive=FALSE)

k_acc_table <- NULL
k_mem_table <- NULL
k_time_table <- NULL

for (i in (1:length(files_k_acc))){
  temp_table <- read.csv(file = files_k_acc[i], header=TRUE, sep=",")
  k_acc_table <- rbind(k_acc_table, temp_table)
}
k_acc_table <- k_acc_table %>% 
  mutate(method = factor(method, levels = c("kmeans", "mbkmeans", "hdf5")), 
         batch_size_perc = factor(scales::percent(k_acc_table$batch_size), 
                             levels = c( "0.1%","1.0%", "10.0%", "20.0%")))
levels(k_acc_table$method) <- c("kmeans-new", "mbkmeans-new", "mbkmean_hdf5-new")

for (i in (1:length(files_k_mem))){
  temp_table <- read.csv(file = files_k_mem[i], header=TRUE, sep=",")
  k_mem_table <- rbind(k_mem_table, temp_table)
}
k_mem_table <- k_mem_table %>% 
  mutate(method = factor(method, levels = c("kmeans", "mbkmeans", "hdf5")), 
         batch_size_perc = factor(scales::percent(k_mem_table$batch_size), 
                             levels = c( "0.1%","1.0%", "10.0%", "20.0%")))
levels(k_mem_table$method) <- c("kmeans-new", "mbkmeans-new", "mbkmean_hdf5-new")

for (i in (1:length(files_k_time))){
  temp_table <- read.csv(file = files_k_time[i], header=TRUE, sep=",")
  k_time_table <- rbind(k_time_table, temp_table)
}
k_time_table <- k_time_table %>% 
  mutate(method = factor(method, levels = c("kmeans", "mbkmeans", "hdf5")), 
         batch_size_perc = factor(scales::percent(k_time_table$batch_size), 
                             levels = c( "0.1%","1.0%", "10.0%", "20.0%")))
levels(k_time_table$method) <- c("kmeans-new", "mbkmeans-new", "mbkmean_hdf5-new")
```

### V-1 Memory vs. Number of Clusters
```{r}
p_mem_k <- k_mem_table %>%
  #dplyr::filter((observations <= 200000))%>%
  dplyr::group_by(method, observations, batch_size_perc, k) %>% 
  dplyr::summarize(mean = mean(memory), 
                   sd = sd(memory)) %>% 
  ggplot(aes(x = k, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Memory Usage for Increasing Number of Clusters [B=5] ") + 
        xlab("Number of clusters") + 
        ylab("Memory (Mb)") + 
  facet_wrap(~batch_size_perc, scales = "free") + 
  theme(legend.position = "top", legend.justification= "center") +
  scale_color_discrete(name = "Method")

p_mem_k
```
### V-2 Time vs. Number of Clusters
```{r}
p_time_k <- k_time_table %>%
  #dplyr::filter((observations <= 200000))%>%
  dplyr::group_by(method, observations, batch_size_perc, k) %>% 
  dplyr::summarize(mean = mean(elapsed_time), 
                   sd = sd(elapsed_time)) %>% 
  ggplot(aes(x = k, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Time for Increasing Number of Clusters [B=10] ") + 
        xlab("Number of clusters") + 
        ylab("Time (Seconds)") + 
  facet_wrap(~batch_size_perc, scales = "free") + 
  theme(legend.position = "top", legend.justification= "center") +
  scale_color_discrete(name = "Method")

p_time_k
```
### V-3 Accuracy vs. Number of Clusters
```{r}
p_acc_k_rnd <- k_acc_table %>%
  dplyr::filter((initializer == "random"))%>%
  dplyr::filter((k >= 10))%>%
  dplyr::group_by(method, observations, batch_size_perc, k) %>% 
  dplyr::summarize(mean = mean(ARI), 
                   sd = sd(ARI)) %>% 
  ggplot(aes(x = k, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "ARI for Increasing Number of Clusters [B=10] ") + 
        xlab("Number of clusters") + 
        ylab("ARI") + 
  facet_wrap(~batch_size_perc, scales = "free") + 
  theme(legend.position = "top", legend.justification= "center") +
  scale_color_discrete(name = "Method")

p_acc_k_rnd
```

```{r}
p_acc_k_kplus <- k_acc_table %>%
  dplyr::filter(!(method == "kmeans-new"))%>%
  dplyr::filter((k >= 10))%>%
  dplyr::group_by(method, observations, batch_size_perc, k, initializer) %>% 
  dplyr::summarize(mean = mean(ARI), 
                   sd = sd(ARI)) %>% 
  ggplot(aes(x = k, y = mean, color = method)) +
          geom_line(aes(linetype=initializer))+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "ARI for Increasing Number of Clusters: Compare Random vs. Kmeans++ [B=10] ") + 
        xlab("Number of Clusters") + 
        ylab("ARI") + 
  facet_grid(method~batch_size_perc, scales = "free") + 
  theme(legend.position = "top", legend.justification= "center") +
  scale_color_discrete(name = "Method")

p_acc_k_kplus
```

```{r}
p_wcss_k_rnd <- k_acc_table %>%
  dplyr::filter((initializer == "random"))%>%
  dplyr::filter((k >= 10))%>%
  dplyr::group_by(method, observations, batch_size_perc, k) %>% 
  dplyr::summarize(mean = mean(WCSS), 
                   sd = sd(WCSS)) %>% 
  ggplot(aes(x = k, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "WCSS for Increasing Number of Clusters [B=10] ") + 
        xlab("Number of Clusters") + 
        ylab("WCSS") + 
  facet_wrap(~batch_size_perc, scales = "free") + 
  theme(legend.position = "top", legend.justification= "center") +
  scale_color_discrete(name = "Method")

p_wcss_k_rnd
```
```{r}
p_wcss_k_kplus <- k_acc_table %>%
  dplyr::filter(!(method == "kmeans-new"))%>%
  dplyr::filter((k >= 10))%>%
  dplyr::group_by(method, observations, batch_size_perc, k, initializer) %>% 
  dplyr::summarize(mean = mean(WCSS), 
                   sd = sd(WCSS)) %>% 
  ggplot(aes(x = k, y = mean, color = method)) +
          geom_line(aes(linetype=initializer))+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "WCSS for Increasing Number of Clusters: Compare Random vs. Kmeans++ [B=10] ") + 
        xlab("Number of Clusters") + 
        ylab("WCSS") + 
  facet_grid(method~batch_size_perc, scales = "free") + 
  theme(legend.position = "top", legend.justification= "center") +
  scale_color_discrete(name = "Method")

p_wcss_k_kplus
```
```{r}
p_iter_k_rnd <- k_acc_table %>%
  dplyr::filter((initializer == "random"))%>%
  dplyr::group_by(method, observations, batch_size_perc, k) %>% 
  dplyr::summarize(mean = mean(iterations), 
                   sd = sd(iterations)) %>% 
  ggplot(aes(x = k, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Number of Iterations for Increasing Number of Clusters [B=10] ") + 
        xlab("Number of cells (thousands)") + 
        ylab("Number of Iterations") + 
  facet_wrap(~batch_size_perc, scales = "free") + 
  theme(legend.position = "top", legend.justification= "center") +
  scale_color_discrete(name = "Method")

p_iter_k_rnd
```

```{r}
p_iter_k_kplus <- k_acc_table %>%
  dplyr::filter(!(method == "kmeans-new"))%>%
  dplyr::filter((k >= 10))%>%
  dplyr::group_by(method, observations, batch_size_perc, k, initializer) %>% 
  dplyr::summarize(mean = mean(iterations), 
                   sd = sd(iterations)) %>% 
  ggplot(aes(x = k, y = mean, color = method)) +
          geom_line(aes(linetype=initializer))+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Number of Iterations for Increasing Number of Clusters: Compare Random vs. Kmeans++ [B=10] ") + 
        xlab("Number of Clusters") + 
        ylab("Number of Iterations") + 
  facet_grid(method~batch_size_perc, scales = "free") + 
  theme(legend.position = "top", legend.justification= "center") +
  scale_color_discrete(name = "Method")

p_iter_k_kplus
```
```{r}
files_max_iters <- list.files(path= here("output_tables", "Varying_k", "mem", "max_iters1"), pattern="*.csv", full.names=TRUE, recursive=FALSE)

max_iters_mem_table <- NULL

for (i in (1:length(files_max_iters))){
  temp_table <- read.csv(file = files_max_iters[i], header=TRUE, sep=",")
  max_iters_mem_table <- rbind(max_iters_mem_table, temp_table)
}
max_iters_mem_table <- max_iters_mem_table %>% 
  mutate(method = factor(method, levels = c("kmeans", "mbkmeans", "hdf5")), 
         batch_size_perc = factor(scales::percent(max_iters_mem_table$batch_size), 
                             levels = c("0.1%","1.0%", "10.0%", "20.0%")), 
         max_iteration = factor(max_iters_mem_table$max_iters, levels = c("10", "1")))  
levels(max_iters_mem_table$method) <- c("kmeans-new", "mbkmeans-new", "mbkmean_hdf5-new")
```

```{r}
p_max_iters_mem <- max_iters_mem_table %>%
  #dplyr::filter((observations <= 200000))%>%
  dplyr::group_by(method, observations, batch_size_perc, k, max_iteration) %>% 
  dplyr::summarize(mean = mean(memory), 
                   sd = sd(memory)) %>% 
  ggplot(aes(x = k, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Assessing One-Iteration Memory Usage for Increasing No. K\n(fixed batch size) [B=2] ") + 
        xlab("Number of Clusters") + 
        ylab("Memory (Mb)") + 
  facet_grid(batch_size_perc~max_iteration, scales = "free") + 
  scale_color_discrete(name = "Method")

p_max_iters_mem
```
```{r}
files_max_iters_time <- list.files(path= here("output_tables", "Varying_k", "time", "max_iters1"), pattern="*.csv", full.names=TRUE, recursive=FALSE)

max_iters_time_table <- NULL

for (i in (1:length(files_max_iters_time))){
  temp_table <- read.csv(file = files_max_iters_time[i], header=TRUE, sep=",")
  max_iters_time_table <- rbind(max_iters_time_table, temp_table)
}
max_iters_time_table <- max_iters_time_table %>% 
  mutate(method = factor(method, levels = c("kmeans", "mbkmeans", "hdf5")), 
         batch_size_perc = factor(scales::percent(max_iters_time_table$batch_size), 
                             levels = c("0.1%","1.0%", "10.0%", "20.0%")), 
         max_iteration = factor(max_iters_time_table$max_iters, levels = c("10", "1")))  
levels(max_iters_time_table$method) <- c("kmeans-new", "mbkmeans-new", "mbkmean_hdf5-new")
```

```{r}
p_max_iters_time <- max_iters_time_table %>%
  #dplyr::filter(!(method == "kmeans-new"))%>%
  dplyr::filter((initializer == "random"))%>%
  #dplyr::filter((observations <= 200000))%>%
  dplyr::group_by(method, observations, batch_size_perc, k, max_iteration) %>% 
  dplyr::summarize(mean = mean(elapsed_time), 
                   sd = sd(elapsed_time)) %>% 
  ggplot(aes(x = k, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Assessing One-Iteration Time for Increasing No. K\n(fixed batch size) [B=10] ") + 
        xlab("Number of Clusters") + 
        ylab("Time (Seconds)") + 
  facet_grid(batch_size_perc~max_iteration, scales = "free") + 
  scale_color_discrete(name = "Method")

p_max_iters_time
```
```{r}
p_max_iters_time_init <- max_iters_time_table %>%
  dplyr::filter(!(method == "kmeans-new"))%>%
  dplyr::filter((max_iters == 10))%>%
  dplyr::group_by(method, observations, batch_size_perc, k, initializer) %>% 
  dplyr::summarize(mean = mean(elapsed_time), 
                   sd = sd(elapsed_time)) %>% 
  ggplot(aes(x = k, y = mean, color = method)) +
          geom_line(aes(linetype=initializer))+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Compare one-iteration time between different initializer [B=10]") + 
        xlab("Number of Clusters") + 
        ylab("Time (Seconds)") + 
  facet_grid(method~batch_size_perc, scales = "free") + 
  theme(legend.position = "top", legend.justification= "center") +
  scale_color_discrete(name = "Method")

p_max_iters_time_init
```

```{r, eval=FALSE}
real_time <- read.csv(file = here("/main/case_studies/output/Output_time.csv"), header=TRUE, sep=",")
real_time <- real_time %>% 
  mutate(method = factor(Method, levels = c("kmeans", "hdf5")), 
         batch_size_perc = factor(scales::percent(real_time$Batch), 
                             levels = c("0.100%", "1.000%")))

real_mem <- read.csv(file = here("/main/case_studies/output/Output_memory.csv"), header=TRUE, sep=",")
```

```{r}
p_case_time <- real_time %>%
  gather(key = "time_type", value = "time", -c(Data:B), -batch_size_perc)%>%
  dplyr::filter(Step %in% c("01_full cluster"))%>%
  dplyr::filter(Data %in% c("tenx_pbmc68k"))%>%
  dplyr::group_by(Data, Step, Method, batch_size_perc, time_type) %>% 
  dplyr::summarize(mean = mean(time), 
                   sd = sd(time)) %>% 
  ggplot(aes(x = Celss/1e3, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "") + 
        xlab("Number of cells (thousands)") + 
        ylab("Time in Seconds") + 
  facet_grid(batch_size_perc~time_type, scale = "free") +
  theme(legend.position = "top", legend.justification= "center") +
  scale_color_discrete(name = "Method")

p_case_time
```

```{r}
files_time <- list.files(path= here("output_tables", "time"), pattern="*.csv", full.names=TRUE, recursive=FALSE)
files_time_old <- list.files(path= here("output_tables", "time", "Before_Patch_0707"), pattern="*.csv", full.names=TRUE, recursive=FALSE)

time_table <- NULL
time_table_old <- NULL

for (i in (1:length(files_time))){
  temp_table <- read.csv(file = files_time[i], header=TRUE, sep=",")
  time_table <- rbind(time_table, temp_table)
}
time_table <- time_table %>% 
  mutate(method = factor(method, levels = c("kmeans", "mbkmeans", "hdf5")), 
         batch_size_perc = factor(scales::percent(time_table$batch_size), 
                             levels = c("0.5%", "1.0%", "5.0%", "10.0%", "20.0%", "50.0%", "80.0%", "100.0%")))
levels(time_table$method) <- c("kmeans-new", "mbkmeans-new", "mbkmean_hdf5-new")

for (i in (1:length(files_time_old))){
  temp_table <- read.csv(file = files_time_old[i], header=TRUE, sep=",")
  time_table_old <- rbind(time_table_old, temp_table)
}
time_table_old <- time_table_old %>% 
  mutate(method = factor(method, levels = c("kmeans", "mbkmeans", "hdf5")), 
         batch_size_perc = factor(scales::percent(time_table_old$batch_size), 
                             levels = c("0.5%", "1.0%", "5.0%", "10.0%", "20.0%", "50.0%", "80.0%", "100.0%")))
levels(time_table_old$method) <- c("kmeans-old", "mbkmeans-old", "mbkmean_hdf5-old")

time_table_total <- rbind(time_table, time_table_old)
```

## I-1 Fix batch size and k (study observation vs. time)
```{r, warning=FALSE, fig.height=20}
p_time_obs <- time_table %>% gather(key = "time_type", value = "time", -c(Data:B), -batch_size_perc)  %>%
  dplyr::group_by(method, observations, batch_size_perc, time_type) %>% 
  dplyr::summarize(mean = mean(time), 
                   sd = sd(time)) %>% 
  ggplot(aes(x = observations/1e3, y = mean, color = method)) +
          geom_line()+
          geom_point()+
          geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                position=position_dodge(0.05))+
        labs(title = "Assessing Time for Increasing No. Obs\n(fixed batch size) [B=10 for small, B=3 for large]") + 
        xlab("Number of cells (thousands)") + 
        ylab("Time (Seconds)") + 
  facet_grid(batch_size_perc~time_type, scale = "free") + 
  scale_color_discrete(name = "Method")

p_time_obs
```